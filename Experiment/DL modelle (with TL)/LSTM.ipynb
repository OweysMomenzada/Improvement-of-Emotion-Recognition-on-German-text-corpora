{"cells":[{"cell_type":"markdown","metadata":{"id":"NME2lbDVTW05"},"source":["###  Long Short-Term Memory model (see Section 3.2. of thesis)\n","\n","This notebook focuses on training and testing the  Long Short-Term Memory  that were proposed in a master's thesis. The model was implemented using TensorFlows.\n","\n","Please keep in mind that these notebooks are primarily used for conducting experiments, live coding, and implementing and evaluating the approaches presented in the thesis. As a result, the code in this notebook may not strictly adhere to best practice coding standards."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"3DQE-dVDTW08","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687551669055,"user_tz":-120,"elapsed":26801,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"}},"outputId":"8d215ddb-6346-46f9-ffa3-e39059ebb254"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import re\n","\n","from nltk.corpus import stopwords\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.utils import shuffle\n","from sklearn.preprocessing import LabelEncoder\n","\n","def import_test_train(local):\n","  \"\"\"\n","  This imports the given train and testset locally or not and returns it.\n","\n","  :param local: If set to true, it will return the trainset from a local view. Otherwise it will open drive mount and attempts to connect to your\n","  drive folders.\n","  \"\"\"\n","\n","  assert type(local) == bool, f\"Type is not valid. Expected boolean, recieved: {type(local)}\"\n","\n","  if local:\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","\n","    df_test = pd.read_csv('/content/gdrive/MyDrive/Experiment/testset_DE_Trigger.csv')\n","    df_train = pd.read_csv('/content/gdrive/MyDrive/Experiment/trainset_DE_Trigger.csv')\n","\n","    return df_test, df_train\n","\n","  else:\n","    import os\n","\n","    # Getting the parent directory\n","    current_directory = os.getcwd()\n","    os.chdir('..')\n","\n","    df_test = pd.read_csv('./Experiment/testset_DE_Trigger.csv')\n","    df_train = pd.read_csv('./Experiment/trainset_DE_Trigger.csv')\n","\n","    return df_test, df_train\n","\n","# importing test and trainset\n","df_test, df_train = import_test_train(True)\n","\n","# If you want to use it locally, make sure to execute the notebooks from the root directory of this project and uncomment the following line:\n","# df_test, df_train = import_test_train(False)"]},{"cell_type":"markdown","metadata":{"id":"raf9SQkfTW1A"},"source":["## Define Labels as numbers"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"7hf4nuSfTW1A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687551741331,"user_tz":-120,"elapsed":614,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"}},"outputId":"eabad19d-eed2-43a1-ee65-68097ddbc3ca"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-493ffa27cf9c>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  tokenizer.fit_on_texts(df_test.append(df_train)[\"content\"].values)\n"]},{"output_type":"stream","name":"stdout","text":["Found 44770 unique tokens.\n"]}],"source":["MAX_NB_WORDS = 39000\n","MAX_SEQUENCE_LENGTH = 150\n","HIDDEN_DIM = 200\n","\n","tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True)\n","tokenizer.fit_on_texts(df_test.append(df_train)[\"content\"].values)\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))"]},{"cell_type":"code","source":["X_train = tokenizer.texts_to_sequences(df_train['content'].values)\n","X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","Y_train = pd.get_dummies(df_train['label']).values\n","\n","X_test = tokenizer.texts_to_sequences(df_test['content'].values)\n","X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","Y_test = pd.get_dummies(df_test['label']).values\n"],"metadata":{"id":"xyAiy3KgPb-V","executionInfo":{"status":"ok","timestamp":1687551742372,"user_tz":-120,"elapsed":1045,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bynSQXtrTW1E"},"source":["## Define model and saving path"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"z9UhJ-uLTW1F","executionInfo":{"status":"ok","timestamp":1687551742373,"user_tz":-120,"elapsed":6,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"}}},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, MaxPool1D, BatchNormalization, Dropout\n","from tensorflow.keras import layers\n","\n","def emotion_model():\n","    model = Sequential()\n","    model.add(Embedding(MAX_NB_WORDS, HIDDEN_DIM, input_length=X_train.shape[1]))\n","    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n","    model.add(BatchNormalization())\n","    model.add(Dense(256,activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(5, activation='softmax'))\n","\n","    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n","              optimizer='adam',metrics=[tf.keras.metrics.AUC()])\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"2xGLFNZJTW1F"},"source":["## Train model"]},{"cell_type":"code","execution_count":7,"metadata":{"scrolled":false,"id":"7sTVyvR6TW1G","executionInfo":{"status":"ok","timestamp":1687551752986,"user_tz":-120,"elapsed":232,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"}}},"outputs":[],"source":["from tensorflow.keras.callbacks import EarlyStopping\n","import os\n","\n","# Set the early stopping criteria\n","early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n","\n","# Create the model\n","model = emotion_model()\n","\n","epochs = 100\n","batch_size = 64\n","\n","# Fit the model with early stopping\n","model.fit(\n","    X_train, Y_train,\n","    epochs=epochs,\n","    batch_size=batch_size,\n","    validation_split=0.1,\n","    callbacks=[early_stopping]\n",")"]},{"cell_type":"markdown","metadata":{"id":"VuhvA23_TW1G"},"source":["### Evaluation"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"3hQLqpxJTW1H","executionInfo":{"status":"ok","timestamp":1687551756267,"user_tz":-120,"elapsed":348,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"}}},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","y_labels = [list(i).index(1) for i in Y_test]\n","Y_pred = np.argmax(model.predict(X_test),axis=1)\n","\n","print(classification_report(y_labels, Y_pred))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}