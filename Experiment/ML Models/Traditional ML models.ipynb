{"cells":[{"cell_type":"markdown","metadata":{"id":"ZVCf-1fCvfSv"},"source":["### Traditional Machine Learning Models (see Section 3.1. of thesis)\n","\n","This notebook focuses on training and testing various traditional Machine Learning models that were proposed in a paper. The models are implemented using Scikit-learn, a popular Machine Learning library. To get the best setup, each model was trained based on the GridSearchCV approach.\n","\n","It's worth noting that the code in this notebook runs entirely on the CPU and does not require a GPU setup.\n","\n","Please keep in mind that these notebooks are primarily used for conducting experiments, live coding, and implementing and evaluating the approaches presented in the thesis. As a result, the code in this notebook may not strictly adhere to best practice coding standards.\n","\n","\n","\n","In summary, this notebook provides an implementation and evaluation of traditional machine learning models using Scikit-learn, with a focus on experimentation and the application of approaches discussed in a paper."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# only execute once\n","import os\n","\n","# Getting the parent directory\n","os.chdir(\"..\")\n","os.chdir(\"..\")"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4313,"status":"ok","timestamp":1687550607520,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"},"user_tz":-120},"id":"pMkFsGt_ZdPe","outputId":"7f12419b-d4d3-4423-bee6-ca911791cc5e"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["import re\n","import string\n","\n","import pandas as pd\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics import classification_report\n","\n","# import the relevant models\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import svm\n","\n","from sklearn.model_selection import GridSearchCV\n","from nltk.corpus import stopwords\n","import nltk\n","\n","# downloading stopwords database\n","nltk.download('stopwords')\n","\n","# importing data with triggerset.\n","\n","def import_test_train(local):\n","  \"\"\"\n","  This imports the given train and testset locally or not and returns it.\n","\n","  :param local: If set to true, it will return the trainset from a local view. Otherwise it will open drive mount and attempts to connect to your\n","  drive folders.\n","  \"\"\"\n","\n","  assert type(local) == bool, f\"Type is not valid. Expected boolean, recieved: {type(local)}\"\n","\n","  if local:\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","\n","    df_test = pd.read_csv('/content/gdrive/MyDrive/Experiment/testset_DE_Trigger.csv')\n","    df_train = pd.read_csv('/content/gdrive/MyDrive/Experiment/trainset_DE_Trigger.csv')\n","\n","    return df_test, df_train\n","\n","  else:\n","    df_test = pd.read_csv('./Experiment/testset_DE_Trigger.csv')\n","    df_train = pd.read_csv('./Experiment/trainset_DE_Trigger.csv')\n","\n","    return df_test, df_train\n","\n","# importing test and trainset\n","df_test, df_train = import_test_train(True)\n","\n","# If you want to use it locally, make sure to execute the notebooks from the root directory of this project and uncomment the following line:\n","# df_test, df_train = import_test_train(False)"]},{"cell_type":"markdown","metadata":{"id":"H5G_MPYf01bG"},"source":["### Simple Feature Engineering"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":626,"status":"ok","timestamp":1687550116209,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"},"user_tz":-120},"id":"m_0S1XthZi-T"},"outputs":[],"source":["# Simple preprocessing of text and removes irrelevant punctuation\n","def process_text(text):\n","    text = str(text).lower()\n","    text = re.sub(\n","        f\"[{re.escape(string.punctuation)}]\", \" \", text\n","    )\n","    text = \" \".join(text.split())\n","    return text\n","\n","# clean train and testset\n","df_test[\"content\"] =  df_test.content.map(process_text)\n","df_train[\"content\"] =  df_train.content.map(process_text)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":229,"status":"ok","timestamp":1687550434026,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"},"user_tz":-120},"id":"swbbjCcJZ0kp"},"outputs":[],"source":["# import german stop words\n","german_stop_words = stopwords.words('german')\n","\n","# delete german stopwords from corpora and create bag-of-words\n","vec = CountVectorizer(\n","    ngram_range=(1, 3),\n","    stop_words=german_stop_words,\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2549,"status":"ok","timestamp":1687550436837,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"},"user_tz":-120},"id":"SXvf_nfnaFNo"},"outputs":[],"source":["# creating a format for the train and testset to be readable for scikit.\n","X_train = vec.fit_transform(df_train.content)\n","X_test = vec.transform(df_test.content)\n","\n","y_train = df_train.label_id\n","y_test = df_test.label_id"]},{"cell_type":"markdown","metadata":{"id":"X7zQ5UqbboDG"},"source":["### K-nearest neighbors\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":212,"status":"ok","timestamp":1687550597425,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"},"user_tz":-120},"id":"sUHOWIyfbOTW"},"outputs":[],"source":["param_grid = {'n_neighbors': [3, 5, 7],\n","              'weights': ['uniform', 'distance'],\n","              'algorithm': ['ball_tree', 'kd_tree', 'brute']}\n","\n","tuned_knn = GridSearchCV(KNeighborsClassifier(),\n","                         param_grid,\n","                         cv=3,\n","                         return_train_score=False)\n","\n","tuned_knn.fit(X_train, y_train)\n","\n","preds = tuned_knn.predict(X_test)\n","print(classification_report(y_test, preds))"]},{"cell_type":"markdown","metadata":{"id":"IReDL348bMn2"},"source":["### NaiveBayes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4711,"status":"ok","timestamp":1677360935649,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"},"user_tz":-60},"id":"TQo5dpINaOEU","outputId":"bc97e4de-0030-4cbc-bc13-f1bb55e7f39f"},"outputs":[],"source":["param_grid = {'alpha': [0.1, 0.5, 1.0, 5.0, 10.0],\n","              'fit_prior': [True, False],\n","              'class_prior': [None, [0.1, 0.9], [0.2, 0.8], [0.4, 0.6], [0.5, 0.5]]}\n","\n","tuned_nb = GridSearchCV(MultinomialNB(),\n","                        param_grid,\n","                        cv=3,\n","                        return_train_score=False)\n","\n","tuned_nb.fit(X_train, y_train)\n","\n","preds = tuned_nb.predict(X_test)\n","print(classification_report(y_test, preds))"]},{"cell_type":"markdown","metadata":{"id":"tJXh_v-wb86h"},"source":["### Decision Tree"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79376,"status":"ok","timestamp":1677361972045,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"},"user_tz":-60},"id":"i_ezJVEVbEAD","outputId":"03ed880e-82eb-4c33-a5de-ebda5ff3f21e"},"outputs":[],"source":["param_grid = {'criterion': ['gini', 'entropy'],\n","              'splitter': ['best', 'random'],\n","              'max_depth': [None, 5, 10, 15],\n","              'min_samples_split': [2, 5, 10],\n","              'min_samples_leaf': [1, 2, 4]}\n","\n","\n","tuned_dt = GridSearchCV(DecisionTreeClassifier(),\n","                        param_grid,\n","                        cv=3,\n","                        return_train_score=False)\n","\n","tuned_dt.fit(X_train, y_train)\n","\n","preds = tuned_dt.predict(X_test)\n","print(classification_report(y_test, preds))"]},{"cell_type":"markdown","metadata":{"id":"Q0pkXqdUcTbm"},"source":["# Support Vector Machine"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314241,"status":"ok","timestamp":1677362307883,"user":{"displayName":"Ovice Moe","userId":"10112058264607559430"},"user_tz":-60},"id":"FCsaROMHcVq7","outputId":"84c22ace-1989-4c9d-a3a1-9d87998b39d5"},"outputs":[],"source":["param_grid = {'C': [0.1, 1, 10],\n","              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n","              'degree': [2, 3, 4],\n","              'gamma': ['scale', 'auto'] + [0.1, 1, 10],\n","              'coef0': [-1, 0, 1]}\n","\n","tuned_svm = GridSearchCV(svm.SVC(),\n","                        param_grid,\n","                        cv=3,\n","                        return_train_score=False)\n","\n","tuned_svm.fit(X_train, y_train)\n","\n","preds = tuned_svm.predict(X_test)\n","print(classification_report(y_test, preds))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN8oDdw0xh7qXvn93LBUxDq","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
